{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa0a0c46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\mosta/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "YOLOv5  2023-9-25 Python-3.8.10 torch-2.0.1+cpu CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import torch\n",
    "from tracker import *\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "import playsound\n",
    "from mutagen.mp3 import MP3\n",
    "import time\n",
    "import miniaudio\n",
    "\n",
    "#get pose from mediapipe\n",
    "mpPose = mp.solutions.pose\n",
    "pose = mpPose.Pose(min_detection_confidence=0.5,min_tracking_confidence=0.5)\n",
    "mpDraw = mp.solutions.drawing_utils\n",
    "\n",
    "\n",
    "\n",
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)\n",
    "\n",
    "cap=cv2.VideoCapture('vid.mp4')\n",
    "\n",
    "\n",
    "tracker = Tracker()\n",
    "c = set()\n",
    "\n",
    "#calculate the angle of the elbow\n",
    "def calc_angle(a,b,c):\n",
    "    a = np.array(a) #armpit=shoulder\n",
    "    b = np.array(b) #elbow\n",
    "    c = np.array(c) #wrist\n",
    "    #arctan means the absolute tan = tan^-1\n",
    "    radians = np.arctan2(c[1]-b[1],c[0]-b[0]) - np.arctan2(a[1]-b[1],a[0]-b[0])\n",
    "    #convert from radian to angle\n",
    "    angle = np.abs(radians*180/np.pi)\n",
    "    #if the arm move in 360d we will subtract it from 360 to be in range 0-180\n",
    "    if angle > 180.0:\n",
    "        angle = 360-angle\n",
    "    return angle\n",
    "\n",
    "file='alarm.mp3'\n",
    "audio = MP3(file)\n",
    "length=audio.info.length\n",
    "\n",
    "frame_check = 7\n",
    "flag = 0\n",
    "#read all frames from the video\n",
    "while True:\n",
    "    ret,frame=cap.read()\n",
    "    if ret==False:\n",
    "        break\n",
    "    #frame=cv2.resize(frame,(1020,500))\n",
    "    results = model(frame)\n",
    "    imgRGB = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    #Apply the mediapipe pose detection module for detection\n",
    "    result = pose.process(imgRGB)\n",
    "    #print(results.pose_landmarks)\n",
    "    h , w , c = frame.shape\n",
    "    # Draw landmarks\n",
    "    if result.pose_landmarks:\n",
    "        #mpDraw.draw_landmarks(frame,result.pose_landmarks, mpPose.POSE_CONNECTIONS)\n",
    "        #get the coor of each landmarks\n",
    "        landmarks = result.pose_landmarks.landmark\n",
    "        \n",
    "        #use the necessary pats only which is shoulder, elbow and wrist\n",
    "        #for land in mpPose.PoseLandmark:\n",
    "            #print(land)\n",
    "        l_shoulder = [landmarks[mpPose.PoseLandmark.LEFT_SHOULDER.value].x,\n",
    "                   landmarks[mpPose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "        r_shoulder = [landmarks[mpPose.PoseLandmark.RIGHT_SHOULDER.value].x,\n",
    "                   landmarks[mpPose.PoseLandmark.RIGHT_SHOULDER.value].y]\n",
    "        \n",
    "        l_elbow = [landmarks[mpPose.PoseLandmark.LEFT_ELBOW.value].x,\n",
    "                   landmarks[mpPose.PoseLandmark.LEFT_ELBOW.value].y]\n",
    "        r_elbow = [landmarks[mpPose.PoseLandmark.RIGHT_ELBOW.value].x,\n",
    "                   landmarks[mpPose.PoseLandmark.RIGHT_ELBOW.value].y]  \n",
    "             \n",
    "        l_wrist = [landmarks[mpPose.PoseLandmark.LEFT_WRIST.value].x,\n",
    "                   landmarks[mpPose.PoseLandmark.LEFT_WRIST.value].y]\n",
    "        r_wrist = [landmarks[mpPose.PoseLandmark.RIGHT_WRIST.value].x,\n",
    "                   landmarks[mpPose.PoseLandmark.RIGHT_WRIST.value].y]\n",
    "\n",
    "        #calculate the angel\n",
    "        l_ang = calc_angle(l_shoulder,l_elbow,l_wrist)\n",
    "        r_ang = calc_angle(r_shoulder,r_elbow,r_wrist)\n",
    "        \n",
    "        #cv2.putText(frame,str(int(l_ang)),tuple(np.multiply(l_elbow,[640,480]).astype(int)),\n",
    "                    #cv2.FONT_HERSHEY_PLAIN,2,(255,255,255),1)\n",
    "        #cv2.putText(frame,str(int(r_ang)),tuple(np.multiply(r_elbow,[640,480]).astype(int)),\n",
    "                    #cv2.FONT_HERSHEY_PLAIN,2,(255,255,255),1)\n",
    "        #1 mean y aixs\n",
    "        if l_wrist[1]*h < l_elbow[1]*h < l_shoulder[1]*h and l_ang > 150:\n",
    "\n",
    "            #if someone still raise his hand for 7 frames,w issues a warning\n",
    "            flag += 1\n",
    "            if flag >= frame_check:\n",
    "                cv2.putText(frame,'Warnning!!! someone need help',(20,75),cv2.FONT_HERSHEY_PLAIN,2,(0,0,255),2)\n",
    "                stream = miniaudio.stream_file(file)\n",
    "                with miniaudio.PlaybackDevice() as device:\n",
    "                    device.start(stream)\n",
    "                    time.sleep(length)\n",
    "            \n",
    "        elif r_wrist[1]*h < r_elbow[1]*h < r_shoulder[1]*h and r_ang > 150:\n",
    "    \n",
    "            flag += 1\n",
    "            if flag >= frame_check:\n",
    "                cv2.putText(frame,'Warnning! someone need help',(20,75),cv2.FONT_HERSHEY_PLAIN,2,(0,0,255),2)\n",
    "                stream = miniaudio.stream_file(file)\n",
    "                with miniaudio.PlaybackDevice() as device:\n",
    "                    device.start(stream)\n",
    "                    time.sleep(length)\n",
    "        \n",
    "        \n",
    "   \n",
    "    points = []\n",
    "    for index , row in results.pandas().xyxy[0].iterrows():\n",
    "        \n",
    "        x1 = int(row['xmin'])\n",
    "        y1 = int(row['ymin'])\n",
    "        x2 = int(row['xmax'])\n",
    "        y2 = int(row['ymax'])\n",
    "        n=(row['name'])\n",
    "        \n",
    "        if 'person' in n:\n",
    "            if row['confidence'] > 0.25:\n",
    "                points.append([x1,y1,x2,y2]) \n",
    "            #cv2.rectangle(frame,(x1,y1),(x2,y2),(255,0,255),2)\n",
    "            #cv2.putText(frame,str(n),(x1,y1),cv2.FONT_HERSHEY_PLAIN,2,(255,0,255),2)\n",
    "    boxes_id = tracker.update(points) \n",
    "    num = len(points)\n",
    "    id = []\n",
    "    #person_id = []\n",
    "    for box_id in boxes_id:\n",
    "        x , y , w , h , idd = box_id\n",
    "        id.append(idd)    \n",
    "            \n",
    "        #cv2.rectangle(frame,(x,y),(w,h),(0,255,0),2)\n",
    "        #cv2.putText(frame,'number of persons is='+str(num),(20,50),cv2.FONT_HERSHEY_PLAIN,2,(255,0,255),3)\n",
    "        #cv2.putText(frame,'person ID is='+str(id[-1]),(x,y),cv2.FONT_HERSHEY_PLAIN,1,(255,0,255),2)\n",
    " \n",
    "  \n",
    "    cv2.imshow('FRAME',frame)\n",
    "    if cv2.waitKey(1)&0xFF==ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
